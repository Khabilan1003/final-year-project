{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityFunction(Enum):\n",
    "    \"\"\"\n",
    "    Similarity functions that are supported.\n",
    "    \"\"\"\n",
    "    \n",
    "    COSINE = 0\n",
    "    EUCLIDEAN = 1\n",
    "    MANHATTAN = 2\n",
    "    DOT_PRODUCT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STSBenchmarkReader:\n",
    "    \"\"\"\n",
    "    STS Benchmark reader to prep the data for evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str = None):\n",
    "        assert data_path != None and os.path.isfile(data_path)\n",
    "        self.data_path = data_path\n",
    "        data_dict = dict(sent1=[], sent2=[], scores=[])\n",
    "\n",
    "        with open(data_path) as fopen:\n",
    "            dataset = list(filter(None, fopen.read().split('\\n')))\n",
    "\n",
    "        sent1 = []\n",
    "        sent2 = []\n",
    "        scores = [] \n",
    "\n",
    "        for data in dataset:\n",
    "            data_list = data.split('\\t')\n",
    "            sent1.append(data_list[5])\n",
    "            sent2.append(data_list[6])\n",
    "            scores.append(data_list[4]) \n",
    "\n",
    "        data_dict['sent1'] = sent1\n",
    "        data_dict['sent2'] = sent2\n",
    "        data_dict['scores'] = scores\n",
    "        # sanity check\n",
    "        assert len(data_dict['sent1']) == len(data_dict['sent2'])\n",
    "        assert len(data_dict['sent1']) == len(data_dict['scores'])\n",
    "\n",
    "        self.data = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import logger\n",
    "\n",
    "\n",
    "class EmbeddingSimilarityEval_STSB:\n",
    "    \"\"\"\n",
    "    Class to compute embeddings, find pair-wise similarity and do model evaluation based on the recommended STS Benchmark test set. \n",
    "    \"\"\"\n",
    "    def __init__(self, model_path_or_str: str, eval_data_path: str, batch_size: int = 16, main_similarity: SimilarityFunction = SimilarityFunction.COSINE, name: str = '', show_progress_bar: bool = False, write_csv: bool = True):\n",
    "        \"\"\"\n",
    "        Constructs an evaluator based for the dataset\n",
    "\n",
    "        The labels need to indicate the similarity between the sentences.\n",
    "        \n",
    "        :param models: Model that you want to evaluate with\n",
    "        :param sentences1:  List with the first sentence in a pair\n",
    "        :param sentences2: List with the second sentence in a pair\n",
    "        :param scores: Similarity score between sentences1[i] and sentences2[i]\n",
    "        :param write_csv: Write results to a CSV file\n",
    "        \"\"\"\n",
    "        assert model_path_or_str != None or model_path_or_str != ''\n",
    "        assert eval_data_path != None or eval_data_path != ''\n",
    "        \n",
    "        stsb = STSBenchmarkReader(eval_data_path)\n",
    "        self.eval_data_path = eval_data_path\n",
    "\n",
    "        self.model = SentenceTransformer(model_path_or_str)\n",
    "        if isinstance(model_path_or_str, str) and (model_path_or_str.find('\\\\') == -1 or model_path_or_str.find('/') == -1):\n",
    "            self.model_name = model_path_or_str\n",
    "        elif os.path.isdir(model_path_or_str) and not model_path_or_str.startswith('http://') and not model_path_or_str.startswith('https://'):\n",
    "            self.model_name = model_path_or_str.split('\\\\')[-1]\n",
    "        \n",
    "        self.sentences1 = stsb.data['sent1']\n",
    "        self.sentences2 = stsb.data['sent2']\n",
    "        self.scores = [float(i) for i in stsb.data['scores']]\n",
    "        self.write_csv = write_csv\n",
    "        self.main_similarity = main_similarity\n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "        if show_progress_bar is None:\n",
    "            show_progress_bar = (logger.getEffectiveLevel() == logging.INFO or logger.getEffectiveLevel() == logging.DEBUG)\n",
    "        self.show_progress_bar = show_progress_bar\n",
    "\n",
    "        self.csv_file = \"similarity_evaluation\"+(\"_\"+name if name else '')+\"_results.csv\"\n",
    "        self.csv_headers = [\"model\", \"stsb_dataset_name\", \"cosine_pearson\", \"cosine_spearman\", \"euclidean_pearson\", \"euclidean_spearman\", \"manhattan_pearson\", \"manhattan_spearman\", \"dot_pearson\", \"dot_spearman\"]\n",
    "        \n",
    "        \n",
    "    def encode_embeddings(self):\n",
    "        all_sent = list()\n",
    "        #note down the sent1 end index\n",
    "        sent1_end_idx = len(self.sentences1)\n",
    "        #join both sent1 and sent2 into the same list\n",
    "        all_sent.extend(self.sentences1)\n",
    "        all_sent.extend(self.sentences2)\n",
    "        self.sentences = all_sent\n",
    "        embeddings = self.model.encode(self.sentences, convert_to_numpy=True, show_progress_bar=self.show_progress_bar)\n",
    "        return embeddings[:sent1_end_idx], embeddings[sent1_end_idx:]\n",
    "   \n",
    "\n",
    "    def run_eval(self, output_path: str = None):\n",
    "        assert self.model_name != None\n",
    "        embeddings1, embeddings2 = self.encode_embeddings()\n",
    "        labels = self.scores\n",
    "        eval_cosine = dict()\n",
    "        eval_manhattan = dict()\n",
    "        eval_euclidean = dict()\n",
    "        eval_dot = dict()\n",
    "        \n",
    "        cosine_scores = 1 - (paired_cosine_distances(embeddings1, embeddings2))\n",
    "        manhattan_distances = -paired_manhattan_distances(embeddings1, embeddings2)\n",
    "        euclidean_distances = -paired_euclidean_distances(embeddings1, embeddings2)\n",
    "        dot_products = [np.dot(emb1, emb2) for emb1, emb2 in zip(embeddings1, embeddings2)]\n",
    "        \n",
    "        eval_cosine['pearson'], _ = pearsonr(labels, cosine_scores)\n",
    "        eval_cosine['spearman'], _ = spearmanr(labels, cosine_scores)\n",
    "        \n",
    "        eval_manhattan['pearson'], _ = pearsonr(labels, manhattan_distances)\n",
    "        eval_manhattan['spearman'], _ = spearmanr(labels, manhattan_distances)\n",
    "\n",
    "        eval_euclidean['pearson'], _ = pearsonr(labels, euclidean_distances)\n",
    "        eval_euclidean['spearman'], _ = spearmanr(labels, euclidean_distances)\n",
    "\n",
    "        eval_dot['pearson'], _ = pearsonr(labels, dot_products)\n",
    "        eval_dot['spearman'], _ = spearmanr(labels, dot_products)\n",
    "\n",
    "        if output_path is not None and self.write_csv:\n",
    "            csv_path = os.path.join(output_path, self.csv_file)\n",
    "            output_file_exists = os.path.isfile(csv_path)\n",
    "            with open(csv_path, mode=\"a\" if output_file_exists else 'w', encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                if not output_file_exists:\n",
    "                    writer.writerow(self.csv_headers)\n",
    "                    \n",
    "                writer.writerow([self.model_name, self.eval_data_path, eval_cosine['pearson'], eval_cosine['spearman'], eval_euclidean['pearson'],\n",
    "                                 eval_euclidean['spearman'], eval_manhattan['pearson'], eval_manhattan['spearman'], eval_dot['pearson'], eval_dot['spearman']])\n",
    "\n",
    "        if self.main_similarity == SimilarityFunction.COSINE:\n",
    "            print(\"Cosine-Similarity :\\tPearson: {:.4f}\\tSpearman: {:.4f}\".format(\n",
    "                eval_cosine['pearson'], eval_cosine['spearman']))\n",
    "            return eval_cosine\n",
    "        elif self.main_similarity == SimilarityFunction.EUCLIDEAN:\n",
    "            return eval_euclidean\n",
    "        elif self.main_similarity == SimilarityFunction.MANHATTAN:\n",
    "            return eval_manhattan\n",
    "        elif self.main_similarity == SimilarityFunction.DOT_PRODUCT:\n",
    "            return eval_dot\n",
    "        elif self.main_similarity is None:\n",
    "            return max(eval_cosine, eval_manhattan, eval_euclidean, eval_dot)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown main_similarity value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 87/87 [01:05<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity :\tPearson: 0.7343\tSpearman: 0.7679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 87/87 [03:45<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity :\tPearson: 0.8418\tSpearman: 0.8347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 87/87 [00:11<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity :\tPearson: 0.8274\tSpearman: 0.8203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 87/87 [03:59<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity :\tPearson: 0.8495\tSpearman: 0.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 87/87 [00:33<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity :\tPearson: 0.7945\tSpearman: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = [\"./sentence_models/bert/\", \"./sentence_models/roberta/\", \"./sentence_models/miniLM/\" , \"./sentence_models/t5/\" , \"./sentence_models/distilbert/\"]\n",
    "\n",
    "eval_data_path=\"./data/sts-test.csv\"\n",
    "output_path=\"./output/\"\n",
    "benchmark_name=\"sts2\"\n",
    "\n",
    "# running for each model\n",
    "for model in model_list:\n",
    "    sts_eval = EmbeddingSimilarityEval_STSB(model, eval_data_path, main_similarity=SimilarityFunction.COSINE, name=benchmark_name, show_progress_bar=True, write_csv=True)\n",
    "    sts_eval.run_eval(output_path=output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" A \"\"Barometer\"\" Neuron enhances stability in...</td>\n",
       "      <td>09-07-1996</td>\n",
       "      <td>5535303</td>\n",
       "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" This invention is a novel high-speed neural ...</td>\n",
       "      <td>19-10-1993</td>\n",
       "      <td>5255349</td>\n",
       "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An optical information processor for use as a ...</td>\n",
       "      <td>17-01-1995</td>\n",
       "      <td>5383042</td>\n",
       "      <td>3 layer liquid crystal neural network with out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>02-01-2001</td>\n",
       "      <td>6169981</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>17-06-2003</td>\n",
       "      <td>6581048</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     patent_abstract patent_date  \\\n",
       "0  \" A \"\"Barometer\"\" Neuron enhances stability in...  09-07-1996   \n",
       "1  \" This invention is a novel high-speed neural ...  19-10-1993   \n",
       "2  An optical information processor for use as a ...  17-01-1995   \n",
       "3  A method and system for intelligent control of...  02-01-2001   \n",
       "4  A method and system for intelligent control of...  17-06-2003   \n",
       "\n",
       "  patent_number                                       patent_title  \n",
       "0       5535303        \"\"\"Barometer\"\" neuron for a neural network\"  \n",
       "1       5255349  \"Electronic neural network for solving \"\"trave...  \n",
       "2       5383042  3 layer liquid crystal neural network with out...  \n",
       "3       6169981  3-brain architecture for an intelligent decisi...  \n",
       "4       6581048  3-brain architecture for an intelligent decisi...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A system for retrieving multimedia information is provided using a computer coupled to a computer-based network, such as the Internet, and particularly the World Wide Web (WWW). The system includes a web browser, a graphic user interface enabled through the web browser to allow a user to input a query representing the information the user wishes to retrieve, and an agent server for producing, training, and evolving first agents and second agents. Each of the first agents retrieves documents (Web page) from the network at a different first network address and at other addresses linked from the document at the first network address. Each of the second agents executes a search on different search engines on the network in accordance with the query to retrieve documents at network addresses provided by the search engine. The system includes a natural language processor which determines the subject categories and important terms of the query, and of the text of each agent retrieved document. The agent server generates and trains an artificial neural network in accordance with the natural language processed query, and embeds the trained artificial neural network in each of the first and second agents. During the search, the first and second agents process through their artificial neural network the subject categories and important terms of each document they retrieve to determine a retrieval value for the document. The graphic user interface displays to the user the addresses of the retrieved documents which are above a threshold retrieval value. The user manually, or the agent server automatically, selects which of the retrieved documents are relevant. Periodically, the artificial neural network of the first and second agents is expanded and retrained by the agent server in accordance with the selected relevant documents to improve their ability to retrieve documents which may be relevant to the query. Further, the agent server can evolve an artificial neural network based on the current artificial neural network, the retrieved documents, and their selected relevancy, by iteratively producing, training, and testing several generations of neural networks to produce an evolved agent. The artificial neural network of the evolved agent then replaces the current artificial neural network used by the agents to search the Internet. One or more concurrent search of the Internet may be provided.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode(big_abstract)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
